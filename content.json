{"meta":{"title":"努力学习NLP","subtitle":null,"description":"苏老泉，二十七，始发奋，读书籍","author":"Fan Yang","url":"https://fanyangfanyang.github.io/blog"},"pages":[{"title":"about","date":"2018-12-13T13:10:03.000Z","updated":"2018-12-13T13:10:03.925Z","comments":true,"path":"about/index.html","permalink":"https://fanyangfanyang.github.io/blog/about/index.html","excerpt":"","text":""}],"posts":[{"title":"结合源码理解Bert","slug":"结合源码理解Bert","date":"2018-12-14T05:47:14.000Z","updated":"2018-12-14T09:26:56.155Z","comments":true,"path":"2018/12/14/结合源码理解Bert/","link":"","permalink":"https://fanyangfanyang.github.io/blog/2018/12/14/结合源码理解Bert/","excerpt":"","text":"摘要&emsp;&emsp;Bert是谷歌于前段时间发布的一个预训练的语言模型，被誉为NLP领域的ImageNet。在共计11项NLP不同领域的评测任务中，Bert均取得了state-of-art的成绩。截至笔者写这篇文章时，squad2.0的leaderboard前7名（包括ensemble和single model）已经全部被结合Bert方法的模型所占领。可以说，这一模型的出现，让大家都必须以一个全新的角度来考虑迁移学习对于NLP的重要性。或者正如许多知名学者所说的那样，Bert正在引领NLP进入一个全新的时代。&emsp;&emsp;本文将从Bert模型的整体结构入手，并结合代码的实现细节来对其进行分析。 Transformer&emsp;&emsp;Transformer是由谷歌在Attention Is ALL You Need一文提出的一种模型。它完全地抛弃了原先在NLP领域应用十分广泛的LSTM结构，转而仅利用Attention机制和全连接层来挖掘文本中蕴含的信息，具体结构如下图所示：&emsp;&emsp;由于不再使用RNN（LSTM）网络结构，这一模型摆脱了输入序列在先后关系上的约束，即可以同时输入与处理同一句子所有单词。这一点极大的提高了模型的并行性，缩短了模型训练所需要的时间。&emsp;&emsp;这一模型最初被应用在机器翻译领域，并在WMT2014的英德翻译、英法翻译评测中，都取得了当时最好的的效果。&emsp;&emsp;如今，包括Bert在内的许多模型，都采用了Transformer的思路，并取得了不错的成绩。具体的结构和代码细节将在下一节中进行详细阐述。 BertTransformer Encoder Block&emsp;&emsp;将Transformer结构应用在语言模型中，Bert并不是首例。以我所知，OpenAI Transformer则更早一些。&emsp;&emsp;不过两者不同的是，OpenAI采用的是Transformer中的Decoder结构，通过Mask机制，遮掩住当前位置后面的词语，来从左到右依次预测句子中的每个词汇，而避免模型提前知道自己将要预测的内容。&emsp;&emsp;而Bert采用的则是Transformer中的Encoder结构，通过最开始就完全遮掩住语料中15%的词汇（具体实现时并不是15%，细节后面会有介绍），然后用句子中的其他部分（包括上文和下文中未被遮掩的词汇）来预测被遮掩的部分。在计算loss时，Bert只统计被遮掩部分的预测结果。另外，Bert还提出了另一个任务，预测两个句子是否是连续存在于文章中的。&emsp;&emsp;从模型整体来看，OpenAI是一个从左到右的单向模型，而Bert则是一个同时考虑上下文的真正的双向模型。从结果上来看，就目前而言，Bert取得了更好的效果。&emsp;&emsp;在这一小节中，我们将着重介绍Bert中应用到的Transformer Encoder Block。&emsp;&emsp;正如上一节中的Transformer结构图所示（左边的部分为Encoder），Encoder主要分为两层：Multi-Head Attention以及Feed Forward。 Multi-Head Attention","categories":[],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://fanyangfanyang.github.io/blog/tags/NLP/"},{"name":"Bert","slug":"Bert","permalink":"https://fanyangfanyang.github.io/blog/tags/Bert/"}],"keywords":[]},{"title":"使用Hexo+Github搭建个人博客","slug":"使用Hexo+Github搭建个人博客","date":"2018-12-13T15:34:55.000Z","updated":"2018-12-14T09:26:24.713Z","comments":true,"path":"2018/12/13/使用Hexo+Github搭建个人博客/","link":"","permalink":"https://fanyangfanyang.github.io/blog/2018/12/13/使用Hexo+Github搭建个人博客/","excerpt":"","text":"一些参考资料&emsp;&emsp;由于本人也是这方面的萌新，所以主要过程都参考的知乎：GitHub+Hexo 搭建个人网站详细教程这篇博客内容很丰富，过程也比较具体，这里就不重复说了。 &emsp;&emsp;我使用的主题是BlueLake具体配置方法在上面的教程中也比较详细，这里也不再赘述。 &emsp;&emsp;MarkDown中文文档 &emsp;&emsp;很好用的Markdown在线编辑网站dillinger &emsp;&emsp;很方便的Markdown语法工具书 遇到的几个问题：1、配置后网页无法显示主题&emsp;&emsp;在更改网站的主题后，生成网页并本地成功预览，然而当完成部署后（并没有报错）,博客网站加载主题格式失败，网页布局混乱。 解决方法：&emsp;&emsp;在站点配置文件（根目录下的_config.yml）中，更改url和root两个属性的值，如下所示： 12url: http://fanyangfanyang.github.io/blogroot: /fanyangfanyang.github.io/ 2、无法连接github库&emsp;&emsp;在使用hexo d进行配置时报错，显示github库连接错误 解决方法：&emsp;&emsp;根目录下的_config.yml文件中的deploy: repo:属性的网址前缀不能使用https。改为http后，错误解决。（似乎还同时解决了文章开头的属性被识别为markdown语言的问题。） 3、段落开头的缩进问题&emsp;&emsp;大概是由于英语中没有缩进的习惯，所以Markdown中你并不能使用空格进行方便的缩进。 解决方法：&emsp;&emsp;可以使用下面三种字符进行首行缩进：123&amp;emsp; //相当于一个中文字符的空格&amp;ensp; //相当于一个英文字符（半个中文字符）的空格&amp;nbsp; //相当于半个英文字符的空格 本人的第一篇博客O(∩_∩)O 未完待续。。","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://fanyangfanyang.github.io/blog/tags/hexo/"},{"name":"Github","slug":"Github","permalink":"https://fanyangfanyang.github.io/blog/tags/Github/"}],"keywords":[]},{"title":"Hello World","slug":"hello-world","date":"2018-12-13T11:31:02.412Z","updated":"2018-12-13T11:31:02.412Z","comments":true,"path":"2018/12/13/hello-world/","link":"","permalink":"https://fanyangfanyang.github.io/blog/2018/12/13/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[],"keywords":[]}]}